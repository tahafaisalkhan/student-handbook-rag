# ğŸ“ Student Handbook RAG

An interactive **Retrieval-Augmented Generation (RAG)** system powered by LangChain, Ollama, FAISS, and Flask. Users can ask natural language questions about the LUMS Student Handbook and get AI-generated answers with context-based retrieval. The project aims to solve the issue of scrolling all 300 pages of the handbook and rather just asking the question they want answered.

https://github.com/user-attachments/assets/e591a81c-b9e9-42b6-a6fa-a25a11f5ab49

---

## ğŸ“¦ Features

- ğŸ” PDF Parsing & Chunking (via PyMuPDF)
- ğŸ§  Semantic Embeddings with `MiniLM-L6-v2`
- âš¡ Local LLM (`Mistral`) served via [Ollama](https://ollama.com/)
- ğŸ” Vector store search with FAISS
- ğŸ’¬ Minimal, modern frontend with TailwindCSS & typing animation
- ğŸ›°ï¸ Dynamic AJAX-based Q&A (no page reloads)

---

## ğŸ› ï¸ Installation & Setup

### 1. Clone the repo
```bash
git clone https://github.com/yourusername/student-handbook-rag.git
cd student-handbook-rag
```

### 2. Set up Python environment
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 3. Start Ollama locally
Make sure Ollama is installed.

```bash
ollama serve         # Terminal tab 1
ollama run mistral   # Terminal tab 2
```

### 4. Build vector store
Extract text from the handbook and generate embeddings:

```bash
cd rag-implementation
jupyter notebook rag.ipynb
```

### 5. Launch Flask app
```bash
cd ..
python app.py
```

Visit `http://127.0.0.1:5000` in your browser.

## ğŸ§  Technologies Used

| Tool | Purpose |
|------|---------|
| LangChain | LLM Orchestration |
| Ollama | Local model server (Mistral) |
| Sentence-Transformers | Embedding models |
| FAISS | Vector similarity search |
| Flask | Backend web framework |
| TailwindCSS | Modern UI styling |

## ğŸ“ Project Structure

```
student-handbook-rag/
â”‚
â”œâ”€â”€ app.py                       # Flask server
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ student_handbook.pdf
â”œâ”€â”€ student_handbook.txt
â”œâ”€â”€ faiss_student_handbook/     # FAISS index files
â”œâ”€â”€ rag-implementation/         # Jupyter notebook to build the vector store
â”‚   â””â”€â”€ rag.ipynb
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html              # Main frontend
â””â”€â”€ venv/                       # Virtual environment
```

## ğŸš€ Deployment

To deploy on Vercel:
1. Use Flask Vercel Adapter
2. Add `vercel.json`:

```json
{
  "builds": [
    { "src": "app.py", "use": "@vercel/python" }
  ],
  "routes": [
    { "src": "/(.*)", "dest": "app.py" }
  ]
}
```

3. Push to GitHub and import into Vercel

## ğŸ™Œ Acknowledgments

Created by **Taha Faisal Khan**

## ğŸ“œ License

MIT License
